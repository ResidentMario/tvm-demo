{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e5c2887-e9e1-48d0-b392-54596654962f",
   "metadata": {},
   "source": [
    "# comparisons\n",
    "\n",
    "This notebook has some timing comparisons between versions of models optimized with TVM and ones that went without. For the sake of simiplicity I'm not going to retrain the models first, I'm just going to grab existing model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584a66c6-3946-4b3d-a211-0840711ecefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .gitignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gitignore\n",
    "\n",
    "mobilenet/\n",
    "unet/\n",
    "tweet-sentiment-extraction/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a0b619-2507-4045-bebd-47145cc1dad1",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5eff05f-701d-41ef-8f03-8cf216d6c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4764185-7d25-4d47-a06d-27ffca08583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97903cb7-9cb7-4ee6-bec2-bb56bcdd2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spell.client\n",
    "client = spell.client.from_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5e92915-1814-46e7-8f6b-5f7902761f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting checkpoints/model_10.pth...\n",
      "Extracting checkpoints/model_5.pth...\n"
     ]
    }
   ],
   "source": [
    "client.resources.cp(\"runs/480\", \"mobilenet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24250ad9-3e10-433f-925f-822be8ce85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/spellml/mobilenet-cifar10/blob/master/models/model_1.py\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
    "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Linear(self.last_channel, n_class)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "mobilenet = MobileNetV2(width_mult=1, n_class=10, input_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f09cc0d0-86c3-432a-91c8-1bb15cd42b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet.load_state_dict(torch.load(os.getcwd() + \"/mobilenet/checkpoints/model_10.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2a4155c-2b88-4160-ab48-c286bd43c34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscript_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_infos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcustom_convert_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdefault_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Load PyTorch model in the form of a scripted PyTorch model and convert into relay.\n",
       "The companion parameters will be handled automatically.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "script_module : TopLevelTracedModule object\n",
       "    TorchScripted PyTorch graph\n",
       "    Note: We currently only support traces (ie: torch.jit.trace(model, input))\n",
       "\n",
       "input_infos : List of tuples\n",
       "    Can be (input name, input shape) or (input name, (input shape, input types))\n",
       "    Graph level input shape and type list\n",
       "    The same input names need to be used for deployment, so choose easy to\n",
       "    remember names (such as: input0, input1)\n",
       "    e.g.\n",
       "    [('input0', (1, 2)), ('input1', (3, 4))]\n",
       "    or\n",
       "    [('input0', ((1, 2), 'int')), ('input1', ((3, 4), 'float'))]\n",
       "\n",
       "custom_convert_map : Dictionary of str to Relay op\n",
       "    A custom op conversion map in the same format as _convert_map above\n",
       "\n",
       "Returns\n",
       "-------\n",
       "mod : tvm.relay.Module\n",
       "    The module that optimizations will be performed on.\n",
       "\n",
       "params : dict of str to tvm.runtime.NDArray\n",
       "    Dict of converted parameters stored in tvm.runtime.ndarray format\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/relay/frontend/pytorch.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relay.frontend.from_pytorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5259e52-23f0-40c3-9f8f-375992ada935",
   "metadata": {},
   "source": [
    "So Relay only supports JIT-traced versions of PyTorch models. [I wrote about tracing in this article](https://spell.ml/blog/pytorch-jit-YBmYuBEAACgAiv71). The easiest way to turn this model into a JIT traced version of itself is to using PyTorch's automatic tracing. This requires no code editing, but it doesn't work with dropout or batchnorm layers. However, idgaf because the accuracy of the model we're brewing here doesn't matter, only its performance delta does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df28ed3b-dfaf-4861-bcba-abc586f69ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2be53e51-6911-4573-8b5e-2f880f18c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /mnt/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80.3%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "85.8%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "91.0%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "96.6%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "99.1%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomPerspective(),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c88443d4-5160-497f-9941-d22ddb07704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ex, y_ex = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b913beb5-ea93-4308-989f-9936d53293bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_mobilenet = torch.jit.trace(mobilenet.forward, (X_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56bba44b-c6c0-4a3e-a3b5-ed11683df11a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.jit._trace.TopLevelTracedModule"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traced_mobilenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ab335-a51c-45b2-8b89-01ab61374d01",
   "metadata": {},
   "source": [
    "TVM needs chipset information. This is pretty much out of my ballzone, but copying the instructions from their tutorial gives me the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a826303-78db-4edd-a8bf-4fdebe620b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name\t: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "model name\t: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "model name\t: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "model name\t: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n"
     ]
    }
   ],
   "source": [
    "!less /proc/cpuinfo | grep \"model name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e913f-2c6f-4f06-9fb7-41d6864b7cdc",
   "metadata": {},
   "source": [
    "Deets from [this overview](https://www.cpu-world.com/CPUs/Xeon/Intel-Xeon%208259CL.html) for this chip. [An example in the documentation](https://tvm.apache.org/docs/tutorials/autotvm/tune_relay_x86.html#define-network) points out that the following target is appropriate for the chip of the type we're looking at here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b55f8bc-e985-4e39-9524-72f15c77e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm -mcpu=skylake-avx512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b9e1d89-e215-4c28-9683-5b0978331ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.relay as relay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae892f71-3012-4bd7-b1ee-3c9af4d9d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_pytorch(traced_mobilenet, input_infos=[('input0', X_ex.shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ab636f-9969-49d8-9732-5052da0d7734",
   "metadata": {},
   "source": [
    "This throws a lot of warnings but...I mean, this is what they document, so this is what I'm going to use lol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6939efe6-b6ad-4f9d-8068-e618bb7c07f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 3, 32, 32), 'float32'), ('TENSOR', (32, 3, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 32, 16, 16), 'float32'), ('TENSOR', (32, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 32, 16, 16), 'float32'), ('TENSOR', (16, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 16, 16, 16), 'float32'), ('TENSOR', (96, 16, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 96, 16, 16), 'float32'), ('TENSOR', (96, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 96, 8, 8), 'float32'), ('TENSOR', (24, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 24, 8, 8), 'float32'), ('TENSOR', (144, 24, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 144, 8, 8), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 144, 8, 8), 'float32'), ('TENSOR', (24, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 144, 8, 8), 'float32'), ('TENSOR', (144, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 144, 4, 4), 'float32'), ('TENSOR', (32, 144, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 32, 4, 4), 'float32'), ('TENSOR', (192, 32, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 192, 4, 4), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 192, 4, 4), 'float32'), ('TENSOR', (32, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 192, 4, 4), 'float32'), ('TENSOR', (192, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 192, 2, 2), 'float32'), ('TENSOR', (64, 192, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 64, 2, 2), 'float32'), ('TENSOR', (384, 64, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 384, 2, 2), 'float32'), ('TENSOR', (384, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 384, 2, 2), 'float32'), ('TENSOR', (64, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 384, 2, 2), 'float32'), ('TENSOR', (96, 384, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 96, 2, 2), 'float32'), ('TENSOR', (576, 96, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 576, 2, 2), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 576, 2, 2), 'float32'), ('TENSOR', (96, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 576, 2, 2), 'float32'), ('TENSOR', (576, 1, 3, 3), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 576, 1, 1), 'float32'), ('TENSOR', (160, 576, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 160, 1, 1), 'float32'), ('TENSOR', (960, 160, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 960, 1, 1), 'float32'), ('TENSOR', (960, 1, 3, 3), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 960, 1, 1), 'float32'), ('TENSOR', (160, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 960, 1, 1), 'float32'), ('TENSOR', (320, 960, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 320, 1, 1), 'float32'), ('TENSOR', (1280, 320, 1, 1), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW', 'NCHW', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('dense_pack.x86', ('TENSOR', (32, 1280), 'float32'), ('TENSOR', (10, 1280), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('dense_pack.x86', ('TENSOR', (32, 1280), 'float32'), ('TENSOR', (1, 1280, 10), 'float32'), None, 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 20, 1, 1, 16), 'float32'), ('TENSOR', (80, 20, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 60, 1, 1, 16), 'float32'), ('TENSOR', (20, 60, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 60, 1, 1, 16), 'float32'), ('TENSOR', (60, 1, 3, 3, 1, 16), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 10, 1, 1, 16), 'float32'), ('TENSOR', (60, 10, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 60, 1, 1, 16), 'float32'), ('TENSOR', (10, 60, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 36, 1, 1, 16), 'float32'), ('TENSOR', (10, 36, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 36, 2, 2, 16), 'float32'), ('TENSOR', (36, 1, 3, 3, 1, 16), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 6, 2, 2, 16), 'float32'), ('TENSOR', (36, 6, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 36, 2, 2, 16), 'float32'), ('TENSOR', (6, 36, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 36, 2, 2, 16), 'float32'), ('TENSOR', (36, 1, 3, 3, 1, 16), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 24, 2, 2, 16), 'float32'), ('TENSOR', (6, 24, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 24, 2, 2, 16), 'float32'), ('TENSOR', (24, 1, 3, 3, 1, 16), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 4, 2, 2, 16), 'float32'), ('TENSOR', (24, 4, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 24, 2, 2, 16), 'float32'), ('TENSOR', (4, 24, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 12, 2, 2, 16), 'float32'), ('TENSOR', (4, 12, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 12, 4, 4, 16), 'float32'), ('TENSOR', (12, 1, 3, 3, 1, 16), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 2, 4, 4, 16), 'float32'), ('TENSOR', (12, 2, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 12, 4, 4, 16), 'float32'), ('TENSOR', (2, 12, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 12, 4, 4, 16), 'float32'), ('TENSOR', (12, 1, 3, 3, 1, 16), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 9, 4, 4, 16), 'float32'), ('TENSOR', (2, 9, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 9, 8, 8, 16), 'float32'), ('TENSOR', (9, 1, 3, 3, 1, 16), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 2, 8, 8, 12), 'float32'), ('TENSOR', (9, 2, 1, 1, 12, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW12c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 12, 8, 8, 12), 'float32'), ('TENSOR', (2, 12, 1, 1, 12, 12), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW12c', 'NCHW12c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 9, 8, 8, 16), 'float32'), ('TENSOR', (9, 1, 3, 3, 1, 16), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 8, 8, 8, 12), 'float32'), ('TENSOR', (2, 8, 1, 1, 12, 12), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW12c', 'NCHW12c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 6, 16, 16, 16), 'float32'), ('TENSOR', (6, 1, 3, 3, 1, 16), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 1, 16, 16, 16), 'float32'), ('TENSOR', (6, 1, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 2, 16, 16, 16), 'float32'), ('TENSOR', (1, 2, 1, 1, 16, 16), 'float32'), (1, 1), (0, 0, 0, 0), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('depthwise_conv2d_NCHWc.x86', ('TENSOR', (32, 2, 16, 16, 16), 'float32'), ('TENSOR', (2, 1, 3, 3, 1, 16), 'float32'), (1, 1), (1, 1, 1, 1), (1, 1), 'NCHW16c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n",
      "Cannot find config for target=llvm -keys=cpu -link-params=0 -mcpu=skylake-avx512, workload=('conv2d_NCHWc.x86', ('TENSOR', (32, 1, 32, 32, 3), 'float32'), ('TENSOR', (2, 1, 3, 3, 3, 16), 'float32'), (2, 2), (1, 1, 1, 1), (1, 1), 'NCHW3c', 'NCHW16c', 'float32'). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23e7392a-d911-44c0-b081-af2120b84502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_executor\n",
    "\n",
    "dev = tvm.device(str(target), 0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b2e9122b-6dac-412d-98bb-ebe28904d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "module.set_input(\"input0\", X_ex)\n",
    "module.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "990b61e3-7095-404d-bee7-e052f889b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = mobilenet(X_ex).shape\n",
    "output_shape = tvm.nd.empty(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7bc8f7de-9150-4756-ab48-04a385a71a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm_output = module.get_output(0, output_shape).asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9915d-97a2-4789-adf4-627fe0617dd5",
   "metadata": {},
   "source": [
    "Numbers for after TVM but before the optimization pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "58162d42-5d78-4dfc-b0bf-f482346dce3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 8.886561410008653, 'median': 8.756740450007783, 'std': 0.3270634636492541}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timing_number = 10\n",
    "timing_repeat = 10\n",
    "unoptimized = (\n",
    "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
    "    * 1000\n",
    "    / timing_number\n",
    ")\n",
    "unoptimized = {\n",
    "    \"mean\": np.mean(unoptimized),\n",
    "    \"median\": np.median(unoptimized),\n",
    "    \"std\": np.std(unoptimized),\n",
    "}\n",
    "\n",
    "print(unoptimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599db50-5387-4787-8400-91169ac13cae",
   "metadata": {},
   "source": [
    "Pre-TVM, post-JIT numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ad34ed2a-2a25-433a-9d21-53d539559b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 357.99847124001644, 'median': 357.83253340005103, 'std': 8.665247280124268}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timing_number = 10\n",
    "timing_repeat = 10\n",
    "unoptimized = (\n",
    "    np.array(timeit.Timer(lambda: traced_mobilenet(X_ex)).repeat(repeat=timing_repeat, number=timing_number))\n",
    "    * 1000\n",
    "    / timing_number\n",
    ")\n",
    "unoptimized = {\n",
    "    \"mean\": np.mean(unoptimized),\n",
    "    \"median\": np.median(unoptimized),\n",
    "    \"std\": np.std(unoptimized),\n",
    "}\n",
    "\n",
    "print(unoptimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3372a1-c6a5-43df-9d9d-7bbd3edbe23f",
   "metadata": {},
   "source": [
    "Pre-JIT numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "93cde7ab-7e5b-4f3e-9732-ca4214dedfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 362.23234594999667, 'median': 363.61967815000753, 'std': 7.793487259223359}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timing_number = 10\n",
    "timing_repeat = 10\n",
    "unoptimized = (\n",
    "    np.array(timeit.Timer(lambda: mobilenet(X_ex)).repeat(repeat=timing_repeat, number=timing_number))\n",
    "    * 1000\n",
    "    / timing_number\n",
    ")\n",
    "unoptimized = {\n",
    "    \"mean\": np.mean(unoptimized),\n",
    "    \"median\": np.median(unoptimized),\n",
    "    \"std\": np.std(unoptimized),\n",
    "}\n",
    "\n",
    "print(unoptimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d7216-6bcb-45a4-aec5-e12115df3715",
   "metadata": {},
   "source": [
    "Hmm, same speed pretty much. So let's just omit the JIT version from the benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "746825ef-6b27-444f-a836-be926493580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.auto_scheduler as auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner\n",
    "from tvm import autotvm\n",
    "\n",
    "# Set up some basic parameters for the runner. The runner takes compiled code\n",
    "# that is generated with a specific set of parameters and measures the\n",
    "# performance of it. ``number`` specifies the number of different\n",
    "# configurations that we will test, while ``repeat`` specifies how many\n",
    "# measurements we will take of each configuration. ``min_repeat_ms`` is a value\n",
    "# that specifies how long need to run configuration test. If the number of\n",
    "# repeats falls under this time, it will be increased. This option is necessary\n",
    "# for accurate tuning on GPUs, and is not required for CPU tuning. Setting this\n",
    "# value to 0 disables it. The ``timeout`` places an upper limit on how long to\n",
    "# run training code for each tested configuration.\n",
    "\n",
    "number = 10\n",
    "repeat = 1\n",
    "min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
    "timeout = 10  # in seconds\n",
    "\n",
    "# create a TVM runner\n",
    "runner = autotvm.LocalRunner(\n",
    "    number=number,\n",
    "    repeat=repeat,\n",
    "    timeout=timeout,\n",
    "    min_repeat_ms=min_repeat_ms,\n",
    ")\n",
    "\n",
    "# Create a simple structure for holding tuning options. We use an XGBoost\n",
    "# algorithim for guiding the search. For a production job, you will want to set\n",
    "# the number of trials to be larger than the value of 10 used here. For CPU we\n",
    "# recommend 1500, for GPU 3000-4000. The number of trials required can depend\n",
    "# on the particular model and processor, so it's worth spending some time\n",
    "# evaluating performance across a range of values to find the best balance\n",
    "# between tuning time and model optimization. Because running tuning is time\n",
    "# intensive we set number of trials to 10, but do not recommend a value this\n",
    "# small. The ``early_stopping`` parameter is the minimum number of trails to\n",
    "# run before a condition that stops the search early can be applied. The\n",
    "# measure option indicates where trial code will be built, and where it will be\n",
    "# run. In this case, we're using the ``LocalRunner`` we just created and a\n",
    "# ``LocalBuilder``. The ``tuning_records`` option specifies a file to write\n",
    "# the tuning data to.\n",
    "\n",
    "tuning_option = {\n",
    "    \"tuner\": \"xgb\",\n",
    "    \"trials\": 10,\n",
    "    \"early_stopping\": 100,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
    "    ),\n",
    "    \"tuning_records\": \"resnet-50-v2-autotuning.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2959d986-3d53-4eee-bc1e-0ac940247eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin by extracting the taks from the pytorch model\n",
    "tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f1aa8df6-4e2e-4825-ac97-9f0e23e5e828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task  1/32]  Current/Best:    0.00/   0.00 GFLOPS | Progress: (0/10) | 0.00 s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/rpc/tracker.py\", line 366, in _tracker_server\n",
      "    handler.run()\n",
      "  File \"/root/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/rpc/tracker.py\", line 361, in run\n",
      "    self._ioloop.start()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/asyncio/base_events.py\", line 586, in run_forever\n",
      "    self._check_running()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/asyncio/base_events.py\", line 578, in _check_running\n",
      "    raise RuntimeError('This event loop is already running')\n",
      "RuntimeError: This event loop is already running\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-9:\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/queues.py\", line 366, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-fcf9cb4c3ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[Task %2d/%2d] \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtuner_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     tuner_obj.tune(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mn_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuning_option\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trials\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuning_option\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"early_stopping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/autotvm/tuner/xgboost_tuner.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=arguments-differ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBTuner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# manually close pool to avoid multiprocessing issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/autotvm/tuner/tuner.py\u001b[0m in \u001b[0;36mtune\u001b[0;34m(self, n_trial, measure_option, early_stopping, callbacks, si_prefix)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mOne\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautotvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSI_PREFIXES\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mSI\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mreporting\u001b[0m \u001b[0mFLOPS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mmeasure_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_measure_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_option\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mn_parallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasure_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_parallel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1e9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/autotvm/measure/measure.py\u001b[0m in \u001b[0;36mcreate_measure_batch\u001b[0;34m(task, option)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"runner\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mattach_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# feed device related information from runner to builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/autotvm/measure/measure_methods.py\u001b[0m in \u001b[0;36mset_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocalRunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/autotvm/measure/measure_methods.py\u001b[0m in \u001b[0;36mset_task\u001b[0;34m(self, task)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Get devices for measurement successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tvm-0.8.dev915+g09df4edb2-py3.9-linux-x86_64.egg/tvm/autotvm/measure/measure_methods.py\u001b[0m in \u001b[0;36mcheck_remote\u001b[0;34m(target, device_key, host, port, priority, timeout)\u001b[0m\n\u001b[1;32m    712\u001b[0m     )\n\u001b[1;32m    713\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/spell/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/spell/lib/python3.9/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/queues.py\", line 365, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/envs/spell/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Tune the extracted tasks sequentially.\n",
    "for i, task in enumerate(tasks):\n",
    "    prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "    tuner_obj = XGBTuner(task, loss_type=\"rank\")\n",
    "    tuner_obj.tune(\n",
    "        n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
    "        early_stopping=tuning_option[\"early_stopping\"],\n",
    "        measure_option=tuning_option[\"measure_option\"],\n",
    "        callbacks=[\n",
    "            autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
    "            autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210aebd5-29f3-468d-bd25-ea061fcf3e43",
   "metadata": {},
   "source": [
    "Ah, this uses an `asyncio` event loop, which cannot be run in this interactive REPL. It _has_ to appear in a `__main__` block, e.g. in a scripting context. The rest of this stuff is going to have to happen in a script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d2260-288e-49dc-b52a-cd344c399f23",
   "metadata": {},
   "source": [
    "## boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7c8a2e29-e3e8-4512-b8cc-e07730f23410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/tvm_funcs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/tvm_funcs.py\n",
    "import tvm\n",
    "import tvm.relay as relay\n",
    "from tvm.contrib import graph_executor\n",
    "import tvm.auto_scheduler as auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner\n",
    "from tvm import autotvm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "TARGET = \"llvm -mcpu=skylake-avx512\"\n",
    "\n",
    "\n",
    "def time_it(model_func):\n",
    "    import timeit\n",
    "\n",
    "    timing_number = 10\n",
    "    timing_repeat = 10\n",
    "    timing = (\n",
    "        np.array(timeit.Timer(model_func).repeat(repeat=timing_repeat, number=timing_number))\n",
    "        * 1000\n",
    "        / timing_number\n",
    "    )\n",
    "    results = {\n",
    "        \"mean\": np.mean(timing),\n",
    "        \"median\": np.median(timing),\n",
    "        \"std\": np.std(timing),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_tvm_model(traced_model, X_ex):\n",
    "    mod, params = relay.frontend.from_pytorch(traced_model, input_infos=[('input0', X_ex.shape)])\n",
    "\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        lib = relay.build(mod, target=TARGET, params=params)\n",
    "\n",
    "    dev = tvm.device(str(TARGET), 0)\n",
    "    module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "\n",
    "    module.set_input(\"input0\", X_ex)\n",
    "    module.run()  # just a test run to make sure it works\n",
    "\n",
    "    # mod is an IR struct. Used downstream. params IDK, used downstream.\n",
    "    # module is a Relay Python collable\n",
    "    return mod, params, module\n",
    "\n",
    "\n",
    "def tune(mod, params, X_ex):\n",
    "    number = 10\n",
    "    repeat = 1\n",
    "    min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
    "    timeout = 10  # in seconds\n",
    "\n",
    "    # create a TVM runner\n",
    "    runner = autotvm.LocalRunner(\n",
    "        number=number,\n",
    "        repeat=repeat,\n",
    "        timeout=timeout,\n",
    "        min_repeat_ms=min_repeat_ms,\n",
    "    )\n",
    "\n",
    "    # Create a simple structure for holding tuning options. We use an XGBoost\n",
    "    # algorithim for guiding the search. For a production job, you will want to set\n",
    "    # the number of trials to be larger than the value of 10 used here. For CPU we\n",
    "    # recommend 1500, for GPU 3000-4000. The number of trials required can depend\n",
    "    # on the particular model and processor, so it's worth spending some time\n",
    "    # evaluating performance across a range of values to find the best balance\n",
    "    # between tuning time and model optimization. Because running tuning is time\n",
    "    # intensive we set number of trials to 10, but do not recommend a value this\n",
    "    # small. The ``early_stopping`` parameter is the minimum number of trails to\n",
    "    # run before a condition that stops the search early can be applied. The\n",
    "    # measure option indicates where trial code will be built, and where it will be\n",
    "    # run. In this case, we're using the ``LocalRunner`` we just created and a\n",
    "    # ``LocalBuilder``. The ``tuning_records`` option specifies a file to write\n",
    "    # the tuning data to.\n",
    "\n",
    "    tuning_option = {\n",
    "        \"tuner\": \"xgb\",\n",
    "        \"trials\": 10,\n",
    "        \"early_stopping\": 100,\n",
    "        \"measure_option\": autotvm.measure_option(\n",
    "            builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
    "        ),\n",
    "        \"tuning_records\": \"resnet-50-v2-autotuning.json\",\n",
    "    }\n",
    "    \n",
    "    tasks = autotvm.task.extract_from_program(mod[\"main\"], target=TARGET, params=params)\n",
    "\n",
    "    for i, task in enumerate(tasks):\n",
    "        prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank\")\n",
    "        tuner_obj.tune(\n",
    "            n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
    "            early_stopping=tuning_option[\"early_stopping\"],\n",
    "            measure_option=tuning_option[\"measure_option\"],\n",
    "            callbacks=[\n",
    "                autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
    "                autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
    "        with tvm.transform.PassContext(opt_level=3, config={}):\n",
    "            lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "    dev = tvm.device(str(target), 0)\n",
    "    optimized_module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "\n",
    "    optimized_module.set_input(\"input0\", X_ex)\n",
    "    optimized_module.run()  # dry run test\n",
    "\n",
    "    return optimized_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0933c828-08fa-4566-8c1c-a9ad429e38f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/test_mobilenet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/test_mobilenet.py\n",
    "# Model code adpated from:\n",
    "# https://github.com/spellml/mobilenet-cifar10/blob/master/models/model_1.py\n",
    "import math\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tvm_funcs import *\n",
    "\n",
    "\n",
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "def make_divisible(x, divisible_by=8):\n",
    "    import numpy as np\n",
    "    return int(np.ceil(x * 1. / divisible_by) * divisible_by)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(inp * expand_ratio)\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=1000, input_size=224, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        assert input_size % 32 == 0\n",
    "        # input_channel = make_divisible(input_channel * width_mult)  # first channel is always 32!\n",
    "        self.last_channel = make_divisible(last_channel * width_mult) if width_mult > 1.0 else last_channel\n",
    "        self.features = [conv_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in interverted_residual_setting:\n",
    "            output_channel = make_divisible(c * width_mult) if t > 1 else c\n",
    "            for i in range(n):\n",
    "                if i == 0:\n",
    "                    self.features.append(block(input_channel, output_channel, s, expand_ratio=t))\n",
    "                else:\n",
    "                    self.features.append(block(input_channel, output_channel, 1, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        self.features.append(conv_1x1_bn(input_channel, self.last_channel))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Linear(self.last_channel, n_class)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    mobilenet = MobileNetV2(width_mult=1, n_class=10, input_size=32)\n",
    "    # mobilenet.load_state_dict(torch.load(\"/mnt/checkpoints/model_10.pth\"))\n",
    "    mobilenet.load_state_dict(torch.load(\"/spell/notebooks/mobilenet/checkpoints/model_10.pth\"))\n",
    "    return mobilenet\n",
    "\n",
    "\n",
    "def get_dataloader():\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomPerspective(),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "    dataset = torchvision.datasets.CIFAR10(\"/mnt/cifar10/\", train=True, transform=transform, download=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mobilenet = get_model()\n",
    "    dataloader = get_dataloader()\n",
    "    X_ex, y_ex = next(iter(dataloader))\n",
    "\n",
    "    traced_mobilenet = torch.jit.trace(mobilenet.forward, (X_ex))\n",
    "\n",
    "    # tvm part\n",
    "    mod, params, module = get_tvm_model(traced_mobilenet, X_ex)\n",
    "    tvm_optimized_module = tune(mod, params, X_ex)\n",
    "\n",
    "    # timing part\n",
    "    print(\"PyTorch timings:\")\n",
    "    print(time_it(lambda: traced_mobilenet(X_ex)))\n",
    "    print(\"TVM (Relay) timings:\")\n",
    "    print(time_it(lambda: module.run()))\n",
    "    print(\"TVM (Tuned) timings:\")\n",
    "    print(time_it(lambda: tvm_optimized_module.run()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985f646-6417-47d8-a9dc-01c8a6a974f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !spell run \\\n",
    "#     --machine-type t4 \\\n",
    "#     --github-url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356a7ad-214a-43d0-9668-d8de2b8c2fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
